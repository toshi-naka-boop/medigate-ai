"""
MediGate AI - ãƒ­ãƒ¼ã‚«ãƒ«MVP
- ç—‡çŠ¶å…¥åŠ› â†’ è¿½åŠ è³ªå• â†’ æ¨å¥¨è¨ºç™‚ç§‘ï¼ˆVertex AI / Geminiï¼‰ â†’ è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯æ¤œç´¢ï¼ˆCSVï¼‰
- èµ·ç‚¹ï¼šç¾åœ¨åœ°ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ï¼‰ï¼‹ æŒ‡å®šé§…ï¼ˆç”°ç”º/ä¸Šé‡/æŸï¼‰
- å—ä»˜çŠ¶æ³ï¼šå—ä»˜ä¸­/ã‚‚ã†ã™ãçµ‚äº†/å—ä»˜å¤–/ä¸æ˜ï¼ˆserviceså´ã§è¨ˆç®—ï¼‰
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import Optional, Tuple, List

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from streamlit_js_eval import get_geolocation

from services.vertex_service import (
    generate_followup_questions,
    generate_department_recommendation,
    generate_pqrst_notes,
)

from services.clinic_dataset_service import (
    load_clinic_dataset,
    search_clinics_near_point,
)

from services.specialist_search_service import search_specialist_info_with_sources
from services.stations import STATIONS


# -------------------------
# Env
# -------------------------
ENV_PATH = Path(__file__).with_name(".env")
load_dotenv(dotenv_path=str(ENV_PATH), override=True)

GOOGLE_CLOUD_PROJECT = os.getenv("GOOGLE_CLOUD_PROJECT")
VERTEX_LOCATION = os.getenv("VERTEX_LOCATION", "asia-northeast1")  # ã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦æ±äº¬æ—¢å®š

ORIGIN_CURRENT = "ç¾åœ¨åœ°ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ï¼‰"
REQUIRED_STATIONS = ["ç”°ç”ºé§…", "ä¸Šé‡é§…", "æŸé§…"]


# -------------------------
# Streamlit config
# -------------------------
st.set_page_config(
    page_title="MediGate AI",
    page_icon="ğŸ¥",
    layout="wide",
)

# -------------------------
# Session state init
# -------------------------
def _init_state():
    ss = st.session_state
    ss.setdefault("symptom", "")
    ss.setdefault("additional_answers", "")
    ss.setdefault("followup_questions", "")
    ss.setdefault("recommendation", "")
    ss.setdefault("disclaimer", "")
    ss.setdefault("pqrst_notes", "")
    ss.setdefault("step", 1)
    ss.setdefault("step3_loaded", False)

    # Cloud Run ãªã©ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒåˆ‡ã‚Šæ›¿ã‚ã‚‹ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ¶ˆãˆã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
    # URL ã® step ã‹ã‚‰å¾©å…ƒã‚’è©¦ã¿ã‚‹ï¼ˆä¸­èº«ã¯ãªã„ã®ã§ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºã™ï¼‰
    qp = st.query_params.get("step")
    if qp and qp.isdigit():
        qp_step = int(qp)
        if qp_step in (2, 3) and not ss.get("symptom", "").strip():
            ss["step"] = qp_step
            ss["_session_expired"] = True

_init_state()


# -------------------------
# Helpers
# -------------------------
@st.cache_data(show_spinner=False)
def _load_dataset_cached():
    return load_clinic_dataset()


def render_header():
    st.title("ğŸ¥ MediGate AI")
    st.caption("ç—‡çŠ¶ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é©åˆ‡ãªè¨ºç™‚ç§‘ã¨è¿‘ãã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã‚’ã”æ¡ˆå†…ã—ã¾ã™ï¼ˆè¨ºæ–­ã¯è¡Œã„ã¾ã›ã‚“ï¼‰")


def get_current_latlng() -> Tuple[Optional[float], Optional[float]]:
    """
    ãƒ–ãƒ©ã‚¦ã‚¶ã®ç¾åœ¨åœ°ã‚’å–å¾—ã€‚å–å¾—ã§ããªã‘ã‚Œã° (None, None) ã‚’è¿”ã™ã€‚
    â€» HTTPS ã¾ãŸã¯ localhost ã§å‹•ä½œã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã§ä½ç½®æƒ…å ±ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚
    """
    loc = get_geolocation()

    if not loc:
        return None, None

    if isinstance(loc, dict) and loc.get("error"):
        return None, None

    # coords å†…ã¾ãŸã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ« (streamlit_js_eval ã®æˆ»ã‚Šå½¢å¼ã«ä¸¡å¯¾å¿œ)
    coords = loc.get("coords") if isinstance(loc, dict) else {}
    if not isinstance(coords, dict):
        coords = {}
    lat = coords.get("latitude") if coords else None
    lng = coords.get("longitude") if coords else None
    if lat is None and isinstance(loc, dict):
        lat = loc.get("latitude")
        lng = loc.get("longitude")

    if lat is None or lng is None:
        return None, None

    try:
        return float(lat), float(lng)
    except (TypeError, ValueError):
        return None, None


def _guess_dept_keywords_from_text(recommendation_text: str) -> List[str]:
    """
    æ¨å¥¨æ–‡ã‹ã‚‰è¨ºç™‚ç§‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é›‘ã«æ¨å®šï¼ˆMVPç”¨ï¼‰
    â€»æœ¬æ¥ã¯ Vertex å´ã§JSONç­‰ã‚’è¿”ã™ã®ãŒç†æƒ³ã€‚
    """
    t = (recommendation_text or "").replace(" ", "").replace("ã€€", "")

    candidates = [
        "å†…ç§‘", "å‘¼å¸å™¨å†…ç§‘", "æ¶ˆåŒ–å™¨å†…ç§‘", "å¾ªç’°å™¨å†…ç§‘", "è…è‡“å†…ç§‘",
        "å°å…ç§‘", "è€³é¼»å’½å–‰ç§‘", "çš®è†šç§‘", "æ•´å½¢å¤–ç§‘", "å¤–ç§‘",
        "å©¦äººç§‘", "æ³Œå°¿å™¨ç§‘", "çœ¼ç§‘", "è„³ç¥çµŒå¤–ç§‘",
        "å¿ƒç™‚å†…ç§‘", "ç²¾ç¥ç§‘",
    ]
    hit = [c for c in candidates if c in t]
    return hit or ["å†…ç§‘"]


def _build_exclude_depts(dept_keywords: List[str]) -> List[str]:
    """
    å†…ç§‘æ¤œç´¢ã«å¿ƒç™‚å†…ç§‘ãŒæ··ã–ã‚‹å•é¡Œã¸ã®ç°¡æ˜“å¯¾å‡¦ã€‚
    ãŸã ã—æ¨å¥¨ãŒãƒ¡ãƒ³ã‚¿ãƒ«ç³»ãªã‚‰é™¤å¤–ã—ãªã„ã€‚
    """
    dept_keywords = dept_keywords or []
    mental = {"å¿ƒç™‚å†…ç§‘", "ç²¾ç¥ç§‘", "ãƒ¡ãƒ³ã‚¿ãƒ«"}
    if any(k in mental for k in dept_keywords):
        return []
    return ["å¿ƒç™‚å†…ç§‘", "ç²¾ç¥ç§‘", "ãƒ¡ãƒ³ã‚¿ãƒ«"]


def _pick_first(row: dict, keys: List[str], default: str = "") -> str:
    for k in keys:
        v = row.get(k)
        if v is None:
            continue
        s = str(v).strip()
        if s:
            return s
    return default


def _render_map_if_possible(df_out):
    """ç·¯åº¦çµŒåº¦ãŒã‚ã‚Œã° st.map ã‚’å‡ºã™ï¼ˆç„¡ã‘ã‚Œã°ä½•ã‚‚ã—ãªã„ï¼‰"""
    if df_out is None or getattr(df_out, "empty", True):
        return

    possible_lat = ["æ‰€åœ¨åœ°åº§æ¨™ï¼ˆç·¯åº¦ï¼‰", "ç·¯åº¦", "lat", "latitude"]
    possible_lng = ["æ‰€åœ¨åœ°åº§æ¨™ï¼ˆçµŒåº¦ï¼‰", "çµŒåº¦", "lng", "lon", "longitude"]

    lat_col = next((c for c in possible_lat if c in df_out.columns), None)
    lng_col = next((c for c in possible_lng if c in df_out.columns), None)
    if not lat_col or not lng_col:
        return

    tmp = df_out[[lat_col, lng_col]].copy()
    tmp.columns = ["lat", "lon"]
    tmp = tmp.dropna()
    if tmp.empty:
        return

    with st.expander("ğŸ—ºï¸ åœ°å›³ã§è¡¨ç¤º", expanded=False):
        st.map(tmp)


def _render_results_block(
    origin_label: str,
    df,
    base_lat: float,
    base_lng: float,
    radius_km: float,
    dept_keywords: List[str],
    exclude_name_keywords: List[str],
    only_accepting_now: bool,
    soon_close_threshold_min: int,
    limit: int,
):
    exclude_dept_keywords = _build_exclude_depts(dept_keywords)

    out = search_clinics_near_point(
        df,
        base_lat,
        base_lng,
        radius_km=radius_km,
        dept_keyword=dept_keywords,
        exclude_dept_keywords=exclude_dept_keywords if exclude_dept_keywords else None,
        exclude_name_keywords=exclude_name_keywords,
        only_accepting_now=only_accepting_now,
        soon_close_threshold_min=soon_close_threshold_min,
        limit=limit,
    )

    if out is None or out.empty:
        st.info("è¿‘ãã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ç·©ã‚ã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
        return

    _render_map_if_possible(out)

    for i, row in enumerate(out.to_dict(orient="records"), 1):
        name = _pick_first(row, ["æ­£å¼åç§°", "åŒ»ç™‚æ©Ÿé–¢åç§°", "åŒ»ç™‚æ©Ÿé–¢å", "åç§°", "name"], default="ï¼ˆåç§°ä¸æ˜ï¼‰")
        addr = _pick_first(row, ["ä½æ‰€", "æ‰€åœ¨åœ°", "æ‰€åœ¨åœ°ä½æ‰€", "æ‰€åœ¨åœ°_ä½æ‰€", "æ‰€åœ¨åœ°ï¼ˆä½æ‰€ï¼‰"])
        dept = _pick_first(row, ["æ¨™ã¼ã†ç§‘ç›®_ä¸€è¦§", "æ¨™ã¼ã†ç§‘ç›®_ä¸€è¦§_ä¸»è¦", "æ¨™æ¦œç§‘ç›®", "è¨ºç™‚ç§‘"])
        status = str(row.get("reception_status", "")).strip()
        next_label = str(row.get("next_reception_label", "")).strip()
        dist = row.get("distance_km", None)
        url = _pick_first(row, ["æ¡ˆå†…ç”¨ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸", "URL", "url"])

        header = f"**{i}. {name}**"
        if status:
            header += f"  â€”  {status}"

        with st.expander(header, expanded=(i <= 3)):
            if addr:
                st.write(f"ğŸ“ {addr}")
            if dept:
                st.write(f"ğŸ·ï¸ æ¨™ã¼ã†ç§‘ç›®: {dept}")
            if next_label:
                st.write(f"â¡ï¸ æ¬¡å›å—ä»˜é–‹å§‹: {next_label}")
            if dist is not None:
                try:
                    st.write(f"ğŸ“ è·é›¢: {float(dist):.2f} km")
                except Exception:
                    pass
            if url:
                # link_button ãŒä½¿ãˆã‚‹å ´åˆã¯ãƒœã‚¿ãƒ³ã€ç„¡ã‘ã‚Œã°ãƒªãƒ³ã‚¯è¡¨ç¤º
                try:
                    st.link_button("å…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã", url)
                except Exception:
                    st.markdown(f"- å…¬å¼ã‚µã‚¤ãƒˆ: {url}")

            # å°‚é–€åŒ»ãƒ»èªå®šåŒ»ãªã©ã®æƒ…å ±ï¼ˆã‚¦ã‚§ãƒ–æ¤œç´¢ãƒ»ã‚½ãƒ¼ã‚¹ä»˜ãï¼‰
            st.markdown("---")
            st.caption("å°‚é–€åŒ»ãƒ»èªå®šåŒ»ãƒ»å­¦ä¼šèªå®šãªã©ã®æƒ…å ±ã‚’ã‚¦ã‚§ãƒ–ã‹ã‚‰æ¤œç´¢ï¼ˆã‚½ãƒ¼ã‚¹ä»˜ãï¼‰")
            clinic_id = str(row.get("ID", "") or f"{origin_label}_{i}")
            cache_key = f"specialist_{clinic_id}"
            if st.button("å°‚é–€åŒ»æƒ…å ±ã‚’ã‚¦ã‚§ãƒ–æ¤œç´¢", key=f"btn_spec_{clinic_id}_{i}"):
                with st.spinner("æ¤œç´¢ä¸­..."):
                    summary, sources = search_specialist_info_with_sources(
                        project_id=GOOGLE_CLOUD_PROJECT or "",
                        clinic_name=name,
                        clinic_url=url or None,
                        departments=dept or None,
                        location=VERTEX_LOCATION,
                    )
                    st.session_state[cache_key] = (summary, sources)
            if cache_key in st.session_state:
                summary, sources = st.session_state[cache_key]
                st.markdown(summary)
                if sources:
                    st.caption("å‚ç…§ã—ãŸã‚½ãƒ¼ã‚¹:")
                    for s in sources:
                        uri = s.get("uri", "").strip()
                        title = (s.get("title") or uri or "(ç„¡é¡Œ)").strip()
                        if uri:
                            st.markdown(f"- [{title}]({uri})")
                        else:
                            st.markdown(f"- {title}")

            st.caption(f"æ¤œç´¢èµ·ç‚¹: {origin_label} / ID: {row.get('ID','')}")


# -------------------------
# Step 1: symptom input
# -------------------------
def render_symptom_input():
    st.header("1. ç—‡çŠ¶å…¥åŠ›")

    symptom = st.text_area(
        "ã©ã®ã‚ˆã†ãªç—‡çŠ¶ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆã§ãã‚‹ç¯„å›²ã§å…·ä½“çš„ã«ï¼‰",
        placeholder="ä¾‹ï¼š3æ—¥å‰ã‹ã‚‰å–‰ãŒç—›ã„ã€‚ç†±ã¯37.8â„ƒã€‚å’³ãŒå°‘ã—å‡ºã‚‹ã€‚æ¯è‹¦ã—ã•ã¯ãªã„ã€‚",
        height=120,
    )

    if st.button("æ¬¡ã¸ï¼ˆè¿½åŠ è³ªå•ã‚’ç”Ÿæˆï¼‰", type="primary"):
        if not symptom.strip():
            st.error("ç—‡çŠ¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        if not GOOGLE_CLOUD_PROJECT:
            st.error("GOOGLE_CLOUD_PROJECT ãŒæœªè¨­å®šã§ã™ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return

        with st.spinner("è¿½åŠ è³ªå•ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
            try:
                questions = generate_followup_questions(
                    GOOGLE_CLOUD_PROJECT,
                    symptom.strip(),
                    VERTEX_LOCATION,
                )
                st.session_state.symptom = symptom.strip()
                st.session_state.followup_questions = questions
                st.session_state.step = 2
                st.query_params["step"] = "2"
                st.rerun()
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# -------------------------
# Step 2: additional answers
# -------------------------
def render_additional_questions():
    st.header("2. è¿½åŠ è³ªå•ã¸ã®å›ç­”")
    st.info("ã‚ˆã‚Šé©åˆ‡ãªè¨ºç™‚ç§‘ã‚’ææ¡ˆã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®è³ªå•ã«åˆ†ã‹ã‚‹ç¯„å›²ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚")

    st.markdown(st.session_state.followup_questions or "ï¼ˆè¿½åŠ è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

    additional_answers = st.text_area(
        "å›ç­”ï¼ˆç®‡æ¡æ›¸ãã§ã‚‚OKï¼‰",
        placeholder="ä¾‹ï¼šç†±ã¯ä»Šæœ37.6â„ƒã€‚å–‰ã®ç—›ã¿ã¯é£²ã¿è¾¼ã‚€ã¨ãå¼·ã„ã€‚æ—¢å¾€æ­´ãªã—ã€‚",
        height=160,
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("æˆ»ã‚‹"):
            st.session_state.step = 1
            if "step" in st.query_params:
                del st.query_params["step"]
            st.rerun()
    with col2:
        if st.button("æ¬¡ã¸ï¼ˆæ¨å¥¨è¨ºç™‚ç§‘ã‚’ç”Ÿæˆï¼‰", type="primary"):
            st.session_state.additional_answers = (additional_answers or "").strip()
            st.session_state.step = 3
            st.query_params["step"] = "3"
            st.rerun()


# -------------------------
# Step 3/4/5: recommendation + clinics + pqrst
# -------------------------
def render_recommendation_and_clinics():
    st.header("3. æ¨å¥¨è¨ºç™‚ç§‘")

    if not GOOGLE_CLOUD_PROJECT:
        st.error("GOOGLE_CLOUD_PROJECT ãŒæœªè¨­å®šã§ã™ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    if not st.session_state.step3_loaded:
        with st.spinner("æ¨å¥¨è¨ºç™‚ç§‘ã¨PQRSTãƒ¡ãƒ¢ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
            try:
                recommendation, disclaimer = generate_department_recommendation(
                    GOOGLE_CLOUD_PROJECT,
                    st.session_state.symptom,
                    st.session_state.additional_answers,
                    VERTEX_LOCATION,
                )
                st.session_state.recommendation = recommendation
                st.session_state.disclaimer = disclaimer
            except Exception as e:
                st.error(f"æ¨å¥¨ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                return

            try:
                pqrst = generate_pqrst_notes(
                    GOOGLE_CLOUD_PROJECT,
                    st.session_state.symptom,
                    st.session_state.additional_answers,
                    VERTEX_LOCATION,
                )
                st.session_state.pqrst_notes = pqrst
            except Exception:
                st.session_state.pqrst_notes = ""

            st.session_state.step3_loaded = True

    st.markdown(st.session_state.recommendation or "")
    if st.session_state.disclaimer:
        st.warning(st.session_state.disclaimer)

    # ---- 4) Clinics ----
    st.header("4. è¿‘ãã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ï¼ˆé§… / ç¾åœ¨åœ°ï¼‰")

    missing = [s for s in REQUIRED_STATIONS if s not in STATIONS]
    if missing:
        st.error(
            "stations.py ã«ä»¥ä¸‹ãŒä¸è¶³ã—ã¦ã„ã¾ã™: "
            + ", ".join(missing)
            + "\nservices/stations.py ã® STATIONS ã«é§…åâ†’(lat,lng) ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
        )
        return

    colA, colB, colC, colD = st.columns([1.2, 1.0, 1.2, 1.0])
    with colA:
        radius_km = st.slider("æ¤œç´¢åŠå¾„ (km)", min_value=0.5, max_value=5.0, value=2.0, step=0.5)
    with colB:
        only_accepting_now = st.checkbox("å—ä»˜ä¸­ã®ã¿è¡¨ç¤º", value=False)
    with colC:
        soon_close_threshold_min = st.slider("ã€ã‚‚ã†ã™ãçµ‚äº†ã€ã®é–¾å€¤ï¼ˆåˆ†ï¼‰", min_value=5, max_value=90, value=30, step=5)
    with colD:
        limit = st.selectbox("è¡¨ç¤ºä»¶æ•°", [5, 10, 20], index=1)

    dept_keywords = _guess_dept_keywords_from_text(st.session_state.recommendation)
    exclude_name_keywords = ["åœ¨å®…", "è¨ªå•", "ãƒ›ãƒ¼ãƒ ã‚±ã‚¢"]  # è¨ªå•è¨ºç™‚ã£ã½ã„åç§°ã‚’é™¤å¤–
    st.caption(f"è¨ºç™‚ç§‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ¨å®šï¼‰: {', '.join(dept_keywords)}")

    origin_options = [ORIGIN_CURRENT] + REQUIRED_STATIONS
    default_origins = [ORIGIN_CURRENT] + REQUIRED_STATIONS

    stations_selected = st.multiselect(
        "æ¤œç´¢èµ·ç‚¹ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰",
        options=origin_options,
        default=default_origins,
    )

    if not stations_selected:
        st.info("æ¤œç´¢èµ·ç‚¹ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    current_latlng = (None, None)
    if ORIGIN_CURRENT in stations_selected:
        st.caption("â€» ç¾åœ¨åœ°ã‚’ä½¿ã†ã«ã¯ **HTTPS** ã¾ãŸã¯ **localhost** ã§é–‹ãã€ãƒ–ãƒ©ã‚¦ã‚¶ã®ä½ç½®æƒ…å ±ã‚’ã€Œè¨±å¯ã€ã«ã—ã¦ãã ã•ã„ã€‚")
        with st.spinner("ç¾åœ¨åœ°ã‚’å–å¾—ã—ã¦ã„ã¾ã™...ï¼ˆè¨±å¯ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒå‡ºãŸã‚‰ã€Œè¨±å¯ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼‰"):
            current_latlng = get_current_latlng()

        if current_latlng == (None, None):
            st.warning(
                "ç¾åœ¨åœ°ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚é§…èµ·ç‚¹ã®ã¿ã§ç¶šè¡Œã—ã¾ã™ã€‚"
                " ãƒ–ãƒ©ã‚¦ã‚¶ã®ä½ç½®æƒ…å ±ãŒã€Œè¨±å¯ã€ã«ãªã£ã¦ã„ã‚‹ã‹ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼å·¦ã®éµãƒãƒ¼ã‚¯ã‹ã‚‰ç¢ºèªã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
            )
            stations_selected = [x for x in stations_selected if x != ORIGIN_CURRENT]

    if not stations_selected:
        st.info("é§…ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    merge_view = st.checkbox("èµ·ç‚¹ã‚’ã¾ã¨ã‚ã¦è¡¨ç¤ºï¼ˆãƒãƒ¼ã‚¸è¡¨ç¤ºï¼‰", value=False)

    df = _load_dataset_cached()

    if merge_view:
        merged_rows = []
        for origin in stations_selected:
            if origin == ORIGIN_CURRENT:
                base_lat, base_lng = current_latlng
            else:
                base_lat, base_lng = STATIONS[origin]

            out = search_clinics_near_point(
                df,
                base_lat,
                base_lng,
                radius_km=radius_km,
                dept_keyword=dept_keywords,
                exclude_dept_keywords=_build_exclude_depts(dept_keywords) or None,
                exclude_name_keywords=exclude_name_keywords,
                only_accepting_now=only_accepting_now,
                soon_close_threshold_min=soon_close_threshold_min,
                limit=limit,
            )

            if out is not None and not out.empty:
                out = out.copy()
                out["æ¤œç´¢èµ·ç‚¹"] = origin
                merged_rows.append(out)

        if not merged_rows:
            st.info("è¿‘ãã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        merged = pd.concat(merged_rows, ignore_index=True)

        sort_cols = []
        if "minutes_to_close" in merged.columns:
            sort_cols.append("minutes_to_close")
        if "distance_km" in merged.columns:
            sort_cols.append("distance_km")
        if sort_cols:
            merged = merged.sort_values(by=sort_cols, ascending=True)

        topn = merged.head(int(limit))
        _render_map_if_possible(topn)

        for i, row in enumerate(topn.to_dict(orient="records"), 1):
            name = _pick_first(row, ["æ­£å¼åç§°", "åŒ»ç™‚æ©Ÿé–¢åç§°", "åŒ»ç™‚æ©Ÿé–¢å", "åç§°", "name"], default="ï¼ˆåç§°ä¸æ˜ï¼‰")
            origin = row.get("æ¤œç´¢èµ·ç‚¹", "")
            status = str(row.get("reception_status", "")).strip()

            header = f"**{i}. {name}**"
            if origin:
                header += f"  â€”  èµ·ç‚¹: {origin}"
            if status:
                header += f"  â€”  {status}"

            with st.expander(header, expanded=(i <= 3)):
                # æ—¢å­˜ãƒ–ãƒ­ãƒƒã‚¯ã‚’å†åˆ©ç”¨
                _render_results_block(
                    origin_label=str(origin),
                    df=df,
                    base_lat=float(row.get("æ‰€åœ¨åœ°åº§æ¨™ï¼ˆç·¯åº¦ï¼‰", current_latlng[0] or 0) or 0),
                    base_lng=float(row.get("æ‰€åœ¨åœ°åº§æ¨™ï¼ˆçµŒåº¦ï¼‰", current_latlng[1] or 0) or 0),
                    radius_km=radius_km,
                    dept_keywords=dept_keywords,
                    exclude_name_keywords=exclude_name_keywords,
                    only_accepting_now=only_accepting_now,
                    soon_close_threshold_min=soon_close_threshold_min,
                    limit=1,
                )
                st.caption(f"ID: {row.get('ID','')}")
    else:
        tabs = st.tabs(stations_selected)
        for tab, origin in zip(tabs, stations_selected):
            with tab:
                st.subheader(f"ğŸ“ {origin} å‘¨è¾º")

                if origin == ORIGIN_CURRENT:
                    if current_latlng == (None, None):
                        st.info("ç¾åœ¨åœ°ã‚’å–å¾—ã§ããªã‹ã£ãŸãŸã‚è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
                        continue
                    base_lat, base_lng = current_latlng
                else:
                    base_lat, base_lng = STATIONS[origin]

                _render_results_block(
                    origin_label=origin,
                    df=df,
                    base_lat=base_lat,
                    base_lng=base_lng,
                    radius_km=radius_km,
                    dept_keywords=dept_keywords,
                    exclude_name_keywords=exclude_name_keywords,
                    only_accepting_now=only_accepting_now,
                    soon_close_threshold_min=soon_close_threshold_min,
                    limit=limit,
                )

    # ---- PQRST ----
    st.header("5. PQRSTãƒ¡ãƒ¢")
    if st.session_state.pqrst_notes:
        st.code(st.session_state.pqrst_notes, language=None)
    else:
        st.info("PQRSTãƒ¡ãƒ¢ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    if st.button("æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        _init_state()
        if "step" in st.query_params:
            del st.query_params["step"]
        st.rerun()


def main():
    render_header()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œæ™‚ï¼ˆCloud Run ã®å†èµ·å‹•ãªã©ã§ step ã ã‘ URL ã‹ã‚‰å¾©å…ƒã—ãŸå ´åˆï¼‰
    if st.session_state.get("_session_expired"):
        st.warning(
            "å‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚Œã¾ã—ãŸï¼ˆã‚µãƒ¼ãƒãƒ¼ãŒå†èµ·å‹•ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚"
            " ä¸‹ã®ãƒœã‚¿ãƒ³ã§æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚"
        )
        if st.button("æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            _init_state()
            st.query_params.clear()
            st.rerun()
        return

    if st.session_state.step == 1:
        render_symptom_input()
    elif st.session_state.step == 2:
        render_additional_questions()
    elif st.session_state.step == 3:
        render_recommendation_and_clinics()


if __name__ == "__main__":
    main()
