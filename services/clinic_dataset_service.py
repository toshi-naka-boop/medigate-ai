# -*- coding: utf-8 -*-
"""
clinic_dataset_service.py
- ã‚¯ãƒªãƒ‹ãƒƒã‚¯CSVã‚’èª­ã¿è¾¼ã¿ã€èµ·ç‚¹(lat,lng)ã‹ã‚‰è¿‘ã„é †ã«æ¤œç´¢
- å—ä»˜ä¸­/ã‚‚ã†ã™ãçµ‚äº†/å—ä»˜å¤–/ä¸æ˜ ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ä»˜ä¸
- æ¬¡å›å—ä»˜é–‹å§‹ãƒ©ãƒ™ãƒ«(next_reception_label) ã‚’ä»˜ä¸
"""

from __future__ import annotations

import math
from dataclasses import dataclass
from datetime import datetime, date, time, timedelta
from pathlib import Path
from typing import Iterable, Optional, Sequence, Union, List

import pandas as pd
from zoneinfo import ZoneInfo


JST = ZoneInfo("Asia/Tokyo")

# CSVã®æƒ³å®šãƒ‘ã‚¹ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ/output/clinics_merged.csvï¼‰
DEFAULT_CSV_PATH = Path(__file__).resolve().parents[1] / "output" / "clinics_merged.csv"

# æœˆ(0)ã€œæ—¥(6) ã§ä½¿ã†æ›œæ—¥ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆCSVåˆ—ã®å…ˆé ­ï¼‰
WEEKDAY_PREFIX = {
    0: "æœˆ",
    1: "ç«",
    2: "æ°´",
    3: "æœ¨",
    4: "é‡‘",
    5: "åœŸ",
    6: "æ—¥",
}

START_SUFFIX = "_å¤–æ¥å—ä»˜é–‹å§‹æ™‚é–“"
END_SUFFIX = "_å¤–æ¥å—ä»˜çµ‚äº†æ™‚é–“"


# -------------------------
# Dataset load
# -------------------------
def load_clinic_dataset(csv_path: Union[str, Path] = DEFAULT_CSV_PATH) -> pd.DataFrame:
    """
    clinics_merged.csv ã‚’èª­ã¿è¾¼ã‚€ã€‚
    æ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯ utf-8-sig ã‚’ç¬¬ä¸€å€™è£œã€å¤±æ•—æ™‚ã¯ cp932 ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    p = Path(csv_path).resolve()
    if not p.exists():
        raise FileNotFoundError(f"CSV not found: {p}")

    # ã¾ãš utf-8-sigï¼ˆBOMã‚ã‚ŠUTF-8ï¼‰ã‚’è©¦ã™
    try:
        df = pd.read_csv(p, encoding="utf-8-sig", low_memory=False)
        return df
    except Exception:
        pass

    # æ¬¡ã« Windowsç³»ã® cp932 ã‚’è©¦ã™
    df = pd.read_csv(p, encoding="cp932", low_memory=False)
    return df


# -------------------------
# Distance
# -------------------------
def _haversine_km(lat1: float, lng1: float, lat2: pd.Series, lng2: pd.Series) -> pd.Series:
    """
    èµ·ç‚¹(lat1,lng1) ã¨ Series(lat2,lng2) ã®è·é›¢(km)ã‚’è¿”ã™ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
    """
    r = 6371.0
    phi1 = math.radians(lat1)
    lam1 = math.radians(lng1)

    phi2 = lat2.astype(float).map(math.radians)
    lam2 = lng2.astype(float).map(math.radians)

    dphi = phi2 - phi1
    dlam = lam2 - lam1

    a = (dphi / 2).map(math.sin).pow(2) + phi2.map(math.cos) * math.cos(phi1) * (dlam / 2).map(math.sin).pow(2)
    c = a.map(math.sqrt).map(lambda x: 2 * math.asin(min(1.0, x)))
    return c * r


# -------------------------
# Time parsing & status
# -------------------------
def _parse_hhmm(x) -> Optional[time]:
    """
    '09:30', '930', '0930', 930 ãªã©ã‚’ time(9,30) ã«å¤‰æ›ã€‚
    """
    if x is None or (isinstance(x, float) and math.isnan(x)):
        return None

    s = str(x).strip()
    if not s:
        return None

    # "9:30"
    if ":" in s:
        parts = s.split(":")
        if len(parts) >= 2:
            try:
                hh = int(parts[0])
                mm = int(parts[1])
                if 0 <= hh <= 23 and 0 <= mm <= 59:
                    return time(hh, mm)
            except Exception:
                return None

    # "930" / "0930"
    # æ•°å­—ä»¥å¤–é™¤å»
    digits = "".join(ch for ch in s if ch.isdigit())
    if len(digits) == 3:
        digits = "0" + digits
    if len(digits) == 4:
        try:
            hh = int(digits[:2])
            mm = int(digits[2:])
            if 0 <= hh <= 23 and 0 <= mm <= 59:
                return time(hh, mm)
        except Exception:
            return None

    return None


def _today_cols(now: datetime) -> tuple[str, str]:
    prefix = WEEKDAY_PREFIX.get(now.weekday(), "æœˆ")
    return f"{prefix}{START_SUFFIX}", f"{prefix}{END_SUFFIX}"


def _make_dt(d: date, t: time) -> datetime:
    return datetime(d.year, d.month, d.day, t.hour, t.minute, tzinfo=JST)


def _minutes_to_close(row: pd.Series, now: datetime) -> Optional[int]:
    """
    ä»Šæ—¥ã®å—ä»˜æ™‚é–“å†…ãªã‚‰çµ‚äº†ã¾ã§ã®æ®‹åˆ†ã‚’è¿”ã™ã€‚å—ä»˜æ™‚é–“å¤–/ä¸æ˜ãªã‚‰ Noneã€‚
    """
    start_col, end_col = _today_cols(now)
    if start_col not in row or end_col not in row:
        return None

    st_t = _parse_hhmm(row.get(start_col))
    ed_t = _parse_hhmm(row.get(end_col))
    if not st_t or not ed_t:
        return None

    start_dt = _make_dt(now.date(), st_t)
    end_dt = _make_dt(now.date(), ed_t)

    # ã‚‚ã—çµ‚äº†ãŒé–‹å§‹ã‚ˆã‚Šæ—©ã„ï¼ˆæ·±å¤œè·¨ãï¼‰ãªã‚‰ç¿Œæ—¥ã«
    if end_dt <= start_dt:
        end_dt = end_dt + timedelta(days=1)

    if start_dt <= now <= end_dt:
        mins = int((end_dt - now).total_seconds() // 60)
        return max(mins, 0)

    return None


def _status_label(minutes_to_close: Optional[int], soon_close_threshold_min: int) -> str:
    """
    minutes_to_close ãŒ None: ä¸æ˜/å—ä»˜å¤–ï¼ˆã“ã“ã§ã¯ä¸€æ—¦ä¸æ˜å¯„ã‚Šï¼‰
    """
    if minutes_to_close is None:
        return "å—ä»˜æ™‚é–“ä¸æ˜/å—ä»˜å¤–"
    if minutes_to_close <= soon_close_threshold_min:
        return "ğŸŸ  ã‚‚ã†ã™ãå—ä»˜çµ‚äº†"
    return "ğŸŸ¢ å—ä»˜ä¸­"


def _next_reception_start(row: pd.Series, now: datetime) -> Optional[datetime]:
    """
    æ¬¡ã«å—ä»˜é–‹å§‹ã™ã‚‹æ—¥æ™‚ã‚’æ¨å®šã—ã¦è¿”ã™ï¼ˆæœ€å¤§7æ—¥å…ˆã¾ã§ï¼‰ã€‚
    ä»Šæ—¥ãŒã¾ã é–‹å§‹å‰ãªã‚‰ä»Šæ—¥ã®é–‹å§‹ã€‚
    """
    base_date = now.date()

    for offset in range(0, 7):
        d = base_date + timedelta(days=offset)
        wd = (now.weekday() + offset) % 7
        prefix = WEEKDAY_PREFIX.get(wd, "æœˆ")

        start_col = f"{prefix}{START_SUFFIX}"
        end_col = f"{prefix}{END_SUFFIX}"

        if start_col not in row or end_col not in row:
            continue

        st_t = _parse_hhmm(row.get(start_col))
        ed_t = _parse_hhmm(row.get(end_col))
        if not st_t or not ed_t:
            continue

        start_dt = _make_dt(d, st_t)
        end_dt = _make_dt(d, ed_t)
        if end_dt <= start_dt:
            end_dt = end_dt + timedelta(days=1)

        if offset == 0:
            # ä»Šæ—¥ï¼šé–‹å§‹å‰ãªã‚‰ startã€å—ä»˜ä¸­ãªã‚‰æ¬¡å›ã¯ä¸è¦(None)ã€çµ‚äº†å¾Œãªã‚‰æ¬¡ã®æ—¥ã¸
            if now < start_dt:
                return start_dt
            if start_dt <= now <= end_dt:
                return None
            # çµ‚äº†å¾Œã¯æ¬¡ã®å€™è£œã¸
        else:
            return start_dt

    return None


def _weekday_jp(dt: datetime) -> str:
    # dt.weekday(): Monday=0
    return WEEKDAY_PREFIX.get(dt.weekday(), "")


def _next_start_label(
    next_start: Optional[datetime],
    now: datetime,
    soon_start_threshold_min: int = 15,
) -> str:
    """
    æ¬¡å›å—ä»˜é–‹å§‹ã®ãƒ©ãƒ™ãƒ«ã‚’ä½œã‚‹ã€‚
    soon_start_threshold_min åˆ†ä»¥å†…ãªã‚‰ã€Œã¾ã‚‚ãªãã€ã‚’ä»˜ã‘ã‚‹ã€‚
    """
    if next_start is None or pd.isna(next_start):
        return ""

    delta_min = int((next_start - now).total_seconds() // 60)
    hhmm = next_start.strftime("%H:%M")

    if next_start.date() == now.date():
        day = "æœ¬æ—¥"
    elif next_start.date() == (now.date() + timedelta(days=1)):
        day = "æ˜æ—¥"
    else:
        day = f"{_weekday_jp(next_start)}æ›œæ—¥"

    prefix = "ã¾ã‚‚ãªã " if 0 <= delta_min <= soon_start_threshold_min else ""
    return f"{prefix}{day} {hhmm}ã€œ"


# -------------------------
# Search main
# -------------------------
def _to_list(x) -> List[str]:
    if x is None:
        return []
    if isinstance(x, str):
        return [x]
    return [str(v) for v in x]


def search_clinics_near_point(
    df: pd.DataFrame,
    base_lat: float,
    base_lng: float,
    *,
    radius_km: float = 2.0,
    dept_keyword: Optional[Union[str, Sequence[str]]] = None,
    exclude_dept_keywords: Optional[Sequence[str]] = None,
    exclude_name_keywords: Optional[Sequence[str]] = None,
    only_accepting_now: bool = False,
    soon_close_threshold_min: int = 30,
    soon_start_threshold_min: int = 15,
    limit: int = 10,
) -> pd.DataFrame:
    """
    è¿‘éš£ã‚¯ãƒªãƒ‹ãƒƒã‚¯æ¤œç´¢ã®ä¸»å‡¦ç†ã€‚

    - èµ·ç‚¹(base_lat, base_lng)ã‹ã‚‰è·é›¢è¨ˆç®—ã— radius_km ä»¥å†…ã«çµã‚‹
    - æ¨™ã¼ã†ç§‘ç›®_ä¸€è¦§ ã§ include/exclude
    - åç§°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§é™¤å¤–
    - å—ä»˜çŠ¶æ³(reception_status)ã€minutes_to_closeã€next_reception_label ã‚’ä»˜ä¸
    - only_accepting_now=True ã®å ´åˆã¯å—ä»˜ä¸­ã®ã¿æ®‹ã™
    - ã‚½ãƒ¼ãƒˆï¼šæ¨å¥¨è¨ºç™‚ç§‘ä¸€è‡´å„ªå…ˆï¼ˆç¬¬ä¸€æ¨å¥¨ç§‘ãƒãƒƒãƒã‚’æœ€å‰ï¼‰â†’ minutes_to_close â†’ distance_km
    """
    if df is None or df.empty:
        return pd.DataFrame()

    work = df.copy()

    # ç·¯åº¦çµŒåº¦åˆ—
    lat_col = "æ‰€åœ¨åœ°åº§æ¨™ï¼ˆç·¯åº¦ï¼‰"
    lng_col = "æ‰€åœ¨åœ°åº§æ¨™ï¼ˆçµŒåº¦ï¼‰"
    if lat_col not in work.columns or lng_col not in work.columns:
        # ä»–ã®åˆ—åã§ã‚‚æ¥ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€MVPã§ã¯å›ºå®šã§
        raise KeyError(f"Missing lat/lng columns: {lat_col}, {lng_col}")

    # numericåŒ– & æ¬ æé™¤å¤–
    work[lat_col] = pd.to_numeric(work[lat_col], errors="coerce")
    work[lng_col] = pd.to_numeric(work[lng_col], errors="coerce")
    work = work.dropna(subset=[lat_col, lng_col])

    # è·é›¢è¨ˆç®— & åŠå¾„ãƒ•ã‚£ãƒ«ã‚¿
    work["distance_km"] = _haversine_km(base_lat, base_lng, work[lat_col], work[lng_col])
    work = work[work["distance_km"] <= float(radius_km)].copy()

    if work.empty:
        return work

    # ãƒ•ã‚£ãƒ«ã‚¿ç”¨ seriesï¼ˆâ€»å¿…ãš work ã® index ã«è¿½å¾“ã•ã›ã‚‹ï¼‰
    name_series = None
    dept_series = None

    # åç§°ï¼ˆå€™è£œåˆ—ï¼‰
    name_cols = [c for c in ["åŒ»ç™‚æ©Ÿé–¢åç§°", "åŒ»ç™‚æ©Ÿé–¢å", "åç§°", "name"] if c in work.columns]
    if name_cols:
        name_series = work[name_cols[0]].astype(str)
    else:
        name_series = pd.Series([""] * len(work), index=work.index)

    # æ¨™ã¼ã†ç§‘ç›®
    dept_col = "æ¨™ã¼ã†ç§‘ç›®_ä¸€è¦§" if "æ¨™ã¼ã†ç§‘ç›®_ä¸€è¦§" in work.columns else None
    if dept_col:
        dept_series = work[dept_col].astype(str)
    else:
        dept_series = pd.Series([""] * len(work), index=work.index)

    # include: è¨ºç™‚ç§‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    dept_keywords = _to_list(dept_keyword)
    if dept_keywords:
        pat = "|".join(map(lambda s: str(s), dept_keywords))
        mask = dept_series.str.contains(pat, na=False)
        work = work[mask].copy()
        # è¿½å¾“æ›´æ–°ï¼ˆreindex warningé¿ã‘ï¼‰
        name_series = name_series.loc[work.index]
        dept_series = dept_series.loc[work.index]

    # exclude: è¨ºç™‚ç§‘é™¤å¤–
    if exclude_dept_keywords:
        pat = "|".join(map(lambda s: str(s), exclude_dept_keywords))
        mask = dept_series.str.contains(pat, na=False)
        work = work[~mask].copy()
        name_series = name_series.loc[work.index]
        dept_series = dept_series.loc[work.index]

    # exclude: åç§°é™¤å¤–
    if exclude_name_keywords:
        pat = "|".join(map(lambda s: str(s), exclude_name_keywords))
        mask = name_series.str.contains(pat, na=False)
        work = work[~mask].copy()
        name_series = name_series.loc[work.index]
        dept_series = dept_series.loc[work.index]

    if work.empty:
        return work

    # å—ä»˜çŠ¶æ³
    now = datetime.now(tz=JST)
    work["minutes_to_close"] = work.apply(lambda r: _minutes_to_close(r, now), axis=1)
    work["reception_status"] = work["minutes_to_close"].apply(
        lambda m: _status_label(m, int(soon_close_threshold_min))
    )

    # æ¬¡å›å—ä»˜é–‹å§‹
    work["next_reception_start"] = work.apply(lambda r: _next_reception_start(r, now), axis=1)
    work["next_reception_label"] = work["next_reception_start"].apply(
        lambda x: _next_start_label(x, now, soon_start_threshold_min=int(soon_start_threshold_min))
    )

    # å—ä»˜ä¸­ã®ã¿
    if only_accepting_now:
        work = work[work["minutes_to_close"].notna()].copy()

    # æ¨å¥¨è¨ºç™‚ç§‘ã®ä¸€è‡´å„ªå…ˆåº¦ï¼ˆç¬¬ä¸€æ¨å¥¨ç§‘ãƒãƒƒãƒ=0, ç¬¬äºŒ=1, ... ãƒãƒƒãƒãªã—=999ï¼‰
    dept_keywords_ordered = _to_list(dept_keyword)
    if dept_keywords_ordered:
        def _row_dept_priority(row: pd.Series) -> int:
            s = dept_series.get(row.name, "") or ""
            for i, kw in enumerate(dept_keywords_ordered):
                if kw and str(kw) in s:
                    return i
            return 999

        work["_sort_dept_priority"] = work.apply(_row_dept_priority, axis=1)
    else:
        work["_sort_dept_priority"] = 0

    # ã‚½ãƒ¼ãƒˆï¼šæ¨å¥¨ç§‘ä¸€è‡´å„ªå…ˆ â†’ å—ä»˜çµ‚äº†ã¾ã§ã®åˆ† â†’ è·é›¢
    work["_sort_mins"] = work["minutes_to_close"].fillna(10**9).astype(int)
    work = work.sort_values(
        by=["_sort_dept_priority", "_sort_mins", "distance_km"],
        ascending=[True, True, True],
    ).drop(columns=["_sort_dept_priority", "_sort_mins"])

    if limit and int(limit) > 0:
        work = work.head(int(limit)).copy()

    return work
